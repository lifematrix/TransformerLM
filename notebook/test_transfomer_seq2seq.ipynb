{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554ea4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/steven/proj/lifematrix/TransformerLM\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ec200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"src/python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca29419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotteddict import dotteddict\n",
    "from transformerlm.train_multi30k_de2en import Trainer\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c448ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_yaml = \"\"\"\n",
    "    batch_size: 128 \n",
    "    device: \"cuda:0\"\n",
    "    n_encoder_layers: 3\n",
    "    n_decoder_layers: 3  \n",
    "    dropout: 0.1\n",
    "    n_epochs: 20\n",
    "    torch_seed: 12345\n",
    "    d_model: 512\n",
    "    d_ff: 512 \n",
    "\"\"\"\n",
    "\n",
    "cfg = dotteddict(yaml.load(config_yaml, yaml.SafeLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d295b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set torch manual seed 12345\n",
      "OrderedDict([('train', ['https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.de.gz', 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.en.gz']), ('val', ['https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.de.gz', 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.en.gz']), ('test', ['https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.de.gz', 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.en.gz'])])\n",
      "OrderedDict([('train', ['/home/steven/proj/lifematrix/TransformerLM/.data/train.de', '/home/steven/proj/lifematrix/TransformerLM/.data/train.en']), ('val', ['/home/steven/proj/lifematrix/TransformerLM/.data/val.de', '/home/steven/proj/lifematrix/TransformerLM/.data/val.en']), ('test', ['/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.de', '/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.en'])])\n",
      "read OrderedDict([('train', ['/home/steven/proj/lifematrix/TransformerLM/.data/train.de', '/home/steven/proj/lifematrix/TransformerLM/.data/train.en']), ('val', ['/home/steven/proj/lifematrix/TransformerLM/.data/val.de', '/home/steven/proj/lifematrix/TransformerLM/.data/val.en']), ('test', ['/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.de', '/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.en'])]) The number of lines: 29000\n",
      "read OrderedDict([('train', ['/home/steven/proj/lifematrix/TransformerLM/.data/train.de', '/home/steven/proj/lifematrix/TransformerLM/.data/train.en']), ('val', ['/home/steven/proj/lifematrix/TransformerLM/.data/val.de', '/home/steven/proj/lifematrix/TransformerLM/.data/val.en']), ('test', ['/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.de', '/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.en'])]) The number of lines: 1014\n",
      "read OrderedDict([('train', ['/home/steven/proj/lifematrix/TransformerLM/.data/train.de', '/home/steven/proj/lifematrix/TransformerLM/.data/train.en']), ('val', ['/home/steven/proj/lifematrix/TransformerLM/.data/val.de', '/home/steven/proj/lifematrix/TransformerLM/.data/val.en']), ('test', ['/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.de', '/home/steven/proj/lifematrix/TransformerLM/.data/test_2016_flickr.en'])]) The number of lines: 1000\n",
      "+----------------------------------------------------------+--------------+------------+\n",
      "|                         Modules                          |     size     | Parameters |\n",
      "+----------------------------------------------------------+--------------+------------+\n",
      "|                src_embedding.0.lut.weight                | [19214, 512] |  9837568   |\n",
      "|          encoder.encoder_layers.0.norm_1.weight          |    [512]     |    512     |\n",
      "|           encoder.encoder_layers.0.norm_1.bias           |    [512]     |    512     |\n",
      "|          encoder.encoder_layers.0.norm_2.weight          |    [512]     |    512     |\n",
      "|           encoder.encoder_layers.0.norm_2.bias           |    [512]     |    512     |\n",
      "| encoder.encoder_layers.0.self_attn.proj_linears.0.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.0.self_attn.proj_linears.0.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.0.self_attn.proj_linears.1.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.0.self_attn.proj_linears.1.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.0.self_attn.proj_linears.2.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.0.self_attn.proj_linears.2.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.0.self_attn.proj_linears.3.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.0.self_attn.proj_linears.3.bias  |    [512]     |    512     |\n",
      "|         encoder.encoder_layers.0.ff.ff.0.weight          |  [512, 512]  |   262144   |\n",
      "|          encoder.encoder_layers.0.ff.ff.0.bias           |    [512]     |    512     |\n",
      "|         encoder.encoder_layers.0.ff.ff.3.weight          |  [512, 512]  |   262144   |\n",
      "|          encoder.encoder_layers.0.ff.ff.3.bias           |    [512]     |    512     |\n",
      "|          encoder.encoder_layers.1.norm_1.weight          |    [512]     |    512     |\n",
      "|           encoder.encoder_layers.1.norm_1.bias           |    [512]     |    512     |\n",
      "|          encoder.encoder_layers.1.norm_2.weight          |    [512]     |    512     |\n",
      "|           encoder.encoder_layers.1.norm_2.bias           |    [512]     |    512     |\n",
      "| encoder.encoder_layers.1.self_attn.proj_linears.0.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.1.self_attn.proj_linears.0.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.1.self_attn.proj_linears.1.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.1.self_attn.proj_linears.1.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.1.self_attn.proj_linears.2.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.1.self_attn.proj_linears.2.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.1.self_attn.proj_linears.3.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.1.self_attn.proj_linears.3.bias  |    [512]     |    512     |\n",
      "|         encoder.encoder_layers.1.ff.ff.0.weight          |  [512, 512]  |   262144   |\n",
      "|          encoder.encoder_layers.1.ff.ff.0.bias           |    [512]     |    512     |\n",
      "|         encoder.encoder_layers.1.ff.ff.3.weight          |  [512, 512]  |   262144   |\n",
      "|          encoder.encoder_layers.1.ff.ff.3.bias           |    [512]     |    512     |\n",
      "|          encoder.encoder_layers.2.norm_1.weight          |    [512]     |    512     |\n",
      "|           encoder.encoder_layers.2.norm_1.bias           |    [512]     |    512     |\n",
      "|          encoder.encoder_layers.2.norm_2.weight          |    [512]     |    512     |\n",
      "|           encoder.encoder_layers.2.norm_2.bias           |    [512]     |    512     |\n",
      "| encoder.encoder_layers.2.self_attn.proj_linears.0.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.2.self_attn.proj_linears.0.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.2.self_attn.proj_linears.1.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.2.self_attn.proj_linears.1.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.2.self_attn.proj_linears.2.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.2.self_attn.proj_linears.2.bias  |    [512]     |    512     |\n",
      "| encoder.encoder_layers.2.self_attn.proj_linears.3.weight |  [512, 512]  |   262144   |\n",
      "|  encoder.encoder_layers.2.self_attn.proj_linears.3.bias  |    [512]     |    512     |\n",
      "|         encoder.encoder_layers.2.ff.ff.0.weight          |  [512, 512]  |   262144   |\n",
      "|          encoder.encoder_layers.2.ff.ff.0.bias           |    [512]     |    512     |\n",
      "|         encoder.encoder_layers.2.ff.ff.3.weight          |  [512, 512]  |   262144   |\n",
      "|          encoder.encoder_layers.2.ff.ff.3.bias           |    [512]     |    512     |\n",
      "|                   encoder.norm.weight                    |    [512]     |    512     |\n",
      "|                    encoder.norm.bias                     |    [512]     |    512     |\n",
      "|                tgt_embedding.0.lut.weight                | [10837, 512] |  5548544   |\n",
      "|          decoder.decoder_layers.0.norm_1.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.0.norm_1.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.0.norm_2.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.0.norm_2.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.0.norm_3.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.0.norm_3.bias           |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.self_attn.proj_linears.0.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.self_attn.proj_linears.0.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.self_attn.proj_linears.1.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.self_attn.proj_linears.1.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.self_attn.proj_linears.2.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.self_attn.proj_linears.2.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.self_attn.proj_linears.3.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.self_attn.proj_linears.3.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.src_attn.proj_linears.0.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.src_attn.proj_linears.0.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.src_attn.proj_linears.1.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.src_attn.proj_linears.1.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.src_attn.proj_linears.2.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.src_attn.proj_linears.2.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.0.src_attn.proj_linears.3.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.0.src_attn.proj_linears.3.bias   |    [512]     |    512     |\n",
      "|         decoder.decoder_layers.0.ff.ff.0.weight          |  [512, 512]  |   262144   |\n",
      "|          decoder.decoder_layers.0.ff.ff.0.bias           |    [512]     |    512     |\n",
      "|         decoder.decoder_layers.0.ff.ff.3.weight          |  [512, 512]  |   262144   |\n",
      "|          decoder.decoder_layers.0.ff.ff.3.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.1.norm_1.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.1.norm_1.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.1.norm_2.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.1.norm_2.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.1.norm_3.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.1.norm_3.bias           |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.self_attn.proj_linears.0.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.self_attn.proj_linears.0.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.self_attn.proj_linears.1.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.self_attn.proj_linears.1.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.self_attn.proj_linears.2.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.self_attn.proj_linears.2.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.self_attn.proj_linears.3.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.self_attn.proj_linears.3.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.src_attn.proj_linears.0.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.src_attn.proj_linears.0.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.src_attn.proj_linears.1.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.src_attn.proj_linears.1.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.src_attn.proj_linears.2.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.src_attn.proj_linears.2.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.1.src_attn.proj_linears.3.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.1.src_attn.proj_linears.3.bias   |    [512]     |    512     |\n",
      "|         decoder.decoder_layers.1.ff.ff.0.weight          |  [512, 512]  |   262144   |\n",
      "|          decoder.decoder_layers.1.ff.ff.0.bias           |    [512]     |    512     |\n",
      "|         decoder.decoder_layers.1.ff.ff.3.weight          |  [512, 512]  |   262144   |\n",
      "|          decoder.decoder_layers.1.ff.ff.3.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.2.norm_1.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.2.norm_1.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.2.norm_2.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.2.norm_2.bias           |    [512]     |    512     |\n",
      "|          decoder.decoder_layers.2.norm_3.weight          |    [512]     |    512     |\n",
      "|           decoder.decoder_layers.2.norm_3.bias           |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.self_attn.proj_linears.0.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.self_attn.proj_linears.0.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.self_attn.proj_linears.1.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.self_attn.proj_linears.1.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.self_attn.proj_linears.2.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.self_attn.proj_linears.2.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.self_attn.proj_linears.3.weight |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.self_attn.proj_linears.3.bias  |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.src_attn.proj_linears.0.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.src_attn.proj_linears.0.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.src_attn.proj_linears.1.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.src_attn.proj_linears.1.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.src_attn.proj_linears.2.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.src_attn.proj_linears.2.bias   |    [512]     |    512     |\n",
      "| decoder.decoder_layers.2.src_attn.proj_linears.3.weight  |  [512, 512]  |   262144   |\n",
      "|  decoder.decoder_layers.2.src_attn.proj_linears.3.bias   |    [512]     |    512     |\n",
      "|         decoder.decoder_layers.2.ff.ff.0.weight          |  [512, 512]  |   262144   |\n",
      "|          decoder.decoder_layers.2.ff.ff.0.bias           |    [512]     |    512     |\n",
      "|         decoder.decoder_layers.2.ff.ff.3.weight          |  [512, 512]  |   262144   |\n",
      "|          decoder.decoder_layers.2.ff.ff.3.bias           |    [512]     |    512     |\n",
      "|                   decoder.norm.weight                    |    [512]     |    512     |\n",
      "|                    decoder.norm.bias                     |    [512]     |    512     |\n",
      "|                  generator.proj.weight                   | [10837, 512] |  5548544   |\n",
      "|                   generator.proj.bias                    |   [10837]    |   10837    |\n",
      "+----------------------------------------------------------+--------------+------------+\n",
      "Total Trainable Params: 33570389, or  32.015M\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450f1e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[0] step[226/227] | loss: 4.0616: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train loss: 5.21290, val loss: 3.90900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[1] step[226/227] | loss: 3.3988: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train loss: 3.60248, val loss: 3.26024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[2] step[226/227] | loss: 3.1193: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | train loss: 3.05448, val loss: 2.93883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[3] step[226/227] | loss: 2.5495: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | train loss: 2.67934, val loss: 2.71379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[4] step[226/227] | loss: 2.3594: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | train loss: 2.38806, val loss: 2.57918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[5] step[226/227] | loss: 2.1595: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | train loss: 2.14964, val loss: 2.47569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[6] step[226/227] | loss: 1.9954: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | train loss: 1.94453, val loss: 2.41208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[7] step[226/227] | loss: 1.7243: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | train loss: 1.76500, val loss: 2.37782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[8] step[226/227] | loss: 1.5147: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | train loss: 1.60548, val loss: 2.34952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[9] step[226/227] | loss: 1.4588: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | train loss: 1.46155, val loss: 2.33550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[10] step[226/227] | loss: 1.2869: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss: 1.33211, val loss: 2.35042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[11] step[226/227] | loss: 1.1053: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train loss: 1.21555, val loss: 2.37358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[12] step[226/227] | loss: 1.2179: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train loss: 1.10593, val loss: 2.38618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[13] step[226/227] | loss: 1.0484: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train loss: 1.00347, val loss: 2.41787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[14] step[226/227] | loss: 0.7903: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train loss: 0.91117, val loss: 2.42582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[15] step[226/227] | loss: 0.9993: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train loss: 0.82584, val loss: 2.45885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[16] step[226/227] | loss: 0.8102: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train loss: 0.75022, val loss: 2.47897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[17] step[226/227] | loss: 0.6785: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train loss: 0.67602, val loss: 2.52536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[18] step[226/227] | loss: 0.6644: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train loss: 0.60843, val loss: 2.57310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch[19] step[226/227] | loss: 0.5972: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 227/227 [00:13<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train loss: 0.54784, val loss: 2.61156\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e425f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> Two cars racing around a racetrack . <eos>\n"
     ]
    }
   ],
   "source": [
    "print(trainer.translate(\"Zwei Autos fahren auf einer Rennstrecke.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bfbdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
